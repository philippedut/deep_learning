{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39fb6aac",
      "metadata": {
        "id": "39fb6aac"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18fc9b35",
      "metadata": {
        "id": "18fc9b35"
      },
      "source": [
        "In this notebook we are trying to optimise the best model form the selection phase to better target each different phylum. In that sense we are splitting the training and the modeling for the different phylumna.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook descripes the experiments that where executed in order to optimise for the validation accuracy of the target variable (family).\n",
        "\n",
        "**The following approach was choosen:**\n",
        "1. A function to implement 3 different\n",
        "augmentations was implemented (random, simple and heavy). These where later used when creating the models to test for optimisation\n",
        "2. These three pretrained models where tested with each of the augmentaion methods\n",
        "- MobileNetv2\n",
        "- ResNet50\n",
        "- EfficientNetB0\n",
        "\n",
        "3. To adress the imbalance of the Phylum, these approaches where tested:\n",
        "- Random oversampling was tested with ResNet50, random augmentation\n",
        "- SMOTE with MobileNetV2, heavy augmentation\n",
        "- Oversampling by duplication with ResNet50, heavy augmentation\n",
        "\n",
        "\n",
        "4. Each experiment was run for between 10 and 50 epochs and for every run, the model with the best validation accuracy was saved as a .keras file\n",
        "\n",
        "\n",
        "5. Solutions: with different approaches, such as ResNet50 with simple augmenation and MobileNetv2 with heavy augmentation, we never reached a score higher than **66%.** This is in coparison to our other Phylums very low.\n",
        "All the experiments to adress the imbalance ended in worse accuracy. This was due to the fact, that SMOTE works by interpolating between feature vectors — and in the case of image data, flattening breaks the spatial structure, and interpolating pixel-by-pixel can create non-realistic or corrupted images that don't follow the original data distribution.\n",
        "Basically making this appraoch worthless :/\n",
        "\n",
        "Our hyphothesis to explain this difference in accuracy compared to our other models is, that cnidaria is a coral and all of the pictures look very similar to each other. That's also why we tried adding noise with the gaussian function from kerase. Unfortunately this did not increase the accuracy as expected."
      ],
      "metadata": {
        "id": "wkTqhf59Xp0H"
      },
      "id": "wkTqhf59Xp0H"
    },
    {
      "cell_type": "markdown",
      "id": "fb015a6a",
      "metadata": {
        "id": "fb015a6a"
      },
      "source": [
        "# Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "156908b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "156908b7",
        "outputId": "189649f0-2cb5-4288-fb99-9113ff8c4780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/rare_species 1.zip'\n",
        "extract_path = '/content/rare_species 1'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321d0f30",
      "metadata": {
        "id": "321d0f30"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import data as tf_data\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Rescaling, RandAugment\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f3d30f",
      "metadata": {
        "id": "26f3d30f"
      },
      "outputs": [],
      "source": [
        "# With colab\n",
        "folder_path = '/content/rare_species 1/rare_species 1'\n",
        "meta = pd.read_csv('/content/rare_species 1//metadata.csv')\n",
        "\n",
        "# With vscode\n",
        "# folder_path = '../data/rare_species 1'\n",
        "# meta = pd.read_csv('../data/rare_species 1/metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7df48b6",
      "metadata": {
        "id": "b7df48b6"
      },
      "outputs": [],
      "source": [
        "print(f\"the diferent Phylum are: \\n{meta['phylum'].unique()}\")\n",
        "print(f\"each phylum contains :  \\n{meta['phylum'].value_counts()}\")\n",
        "\n",
        "print(f\"their is {meta['family'].nunique()} different families\")\n",
        "\n",
        "meta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52f482a0",
      "metadata": {
        "id": "52f482a0"
      },
      "source": [
        "# Phylum Splits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f288916",
      "metadata": {
        "id": "2f288916"
      },
      "source": [
        "This code splits the species into separate folders based on their phylum.  \n",
        "This organization allows us to train a dedicated model for each phylum more effectively.<br>\n",
        "(we repeat this proses in each notebook only because we are using colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5139bbc",
      "metadata": {
        "id": "c5139bbc"
      },
      "outputs": [],
      "source": [
        "# With colab\n",
        "current_locations = '/content/rare_species 1'\n",
        "\n",
        "# with vscode\n",
        "# current_locations = '../data/rare_species 1'\n",
        "\n",
        "for _, row in meta.iterrows():\n",
        "\n",
        "    phylum = row['phylum']\n",
        "    file_path = row['file_path']\n",
        "\n",
        "\n",
        "    file_location = os.path.join(current_locations, file_path)\n",
        "\n",
        "    # create a a detination folder keeping the subfolder structure\n",
        "\n",
        "        # with colab\n",
        "    target_folder = os.path.join(phylum, os.path.dirname(file_path))\n",
        "\n",
        "        # with vscode\n",
        "    # target_folder = os.path.join(\"../data\" , phylum, os.path.dirname(file_path))\n",
        "\n",
        "    os.makedirs(target_folder, exist_ok=True)  # Make sure the folder exists\n",
        "\n",
        "    # Final destination path\n",
        "    destination = os.path.join(target_folder, os.path.basename(file_path))\n",
        "\n",
        "    # Copy the file if it exists\n",
        "    if os.path.exists(file_location):\n",
        "        shutil.copy2(file_location, destination)\n",
        "    else:\n",
        "        print(f\"Couldn't find the file: {file_location}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cba5d283",
      "metadata": {
        "id": "cba5d283"
      },
      "source": [
        "# Train Val Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d127908",
      "metadata": {
        "id": "3d127908"
      },
      "outputs": [],
      "source": [
        "# with colab\n",
        "path_phylum_cnidaria = \"/content/cnidaria\"\n",
        "\n",
        "# with vscode\n",
        "# path_phylum_chordata = \"../data/chordata\"\n",
        "\n",
        "image_size = (224, 224)\n",
        "seed = 42\n",
        "batch_size = 32\n",
        "\n",
        "train_ds_cnidaria, val_ds_cnidaria = keras.utils.image_dataset_from_directory(\n",
        "    path_phylum_cnidaria,\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=seed,\n",
        "    image_size= image_size,\n",
        "    batch_size= batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef90f70c",
      "metadata": {
        "id": "ef90f70c"
      },
      "outputs": [],
      "source": [
        "def display_images(train_ds, augmentation_type=\"simple\"):\n",
        "    for images, labels in train_ds.take(1):\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)\n",
        "            plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
        "            plt.title(int(labels[i]))\n",
        "            plt.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "display_images(train_ds_cnidaria)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a236b02f",
      "metadata": {
        "id": "a236b02f"
      },
      "source": [
        "# Augmentation layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for Augmentation variants and applying them."
      ],
      "metadata": {
        "id": "5ZRwVeneumau"
      },
      "id": "5ZRwVeneumau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef60d1e",
      "metadata": {
        "id": "5ef60d1e"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(images, augmentation_type=\"simple\"):\n",
        "    augmentation_layer = data_augmentation_layers[augmentation_type]\n",
        "    return augmentation_layer(images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different Augemantations to try models with\n",
        "data_augmentation_layers = {\n",
        "    # All random Augmentation\n",
        "    \"randaugment\": RandAugment(value_range=(0, 255)),\n",
        "    # Simple, with just random rotation\n",
        "    \"simple\": keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.2),\n",
        "    ]),\n",
        "    # Heavy, also adding Noise with the Gaussian function\n",
        "    \"heavy\": keras.Sequential([\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.5),\n",
        "        layers.RandomZoom(0.4),\n",
        "        layers.RandomContrast(0.3),\n",
        "        layers.RandomBrightness(factor=0.2),\n",
        "        layers.RandomShear(fill_mode='reflect'),\n",
        "        layers.RandomCrop(height=224, width=224),\n",
        "        layers.GaussianNoise(0.2)\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "oOlwrysnEDR0"
      },
      "id": "oOlwrysnEDR0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9bfca3fb",
      "metadata": {
        "id": "9bfca3fb"
      },
      "source": [
        "--------------\n",
        "# Models\n",
        "\n",
        "\n",
        "Test these 3 different models with simple Augmentation:\n",
        "1. MobileNetv2\n",
        "2. ResNet50\n",
        "3. EfficientNetB0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNetV2"
      ],
      "metadata": {
        "id": "QC7JVryWG0dk"
      },
      "id": "QC7JVryWG0dk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a9763d",
      "metadata": {
        "id": "11a9763d"
      },
      "outputs": [],
      "source": [
        "# Create a function to create mobilenetv2 model\n",
        "def make_model_mobilenetv2(input_shape, num_classes, augmentation_type=\"simple\"):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Rescaling layer\n",
        "    x = data_augmentation(inputs) # Remove the extra (inputs) call here\n",
        "    x = Rescaling(1./255)(x)\n",
        "\n",
        "    # Pretrained MobileNetV2 base\n",
        "    base_model = MobileNetV2(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "    base_model.trainable = False  # Freeze for transfer learning\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.1)(x)  # Optional regularization\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff0830f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aff0830f",
        "outputId": "7d8010fe-29de-4632-9e8c-e1811a94d078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-bff34261da3a>:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(include_top=False, input_tensor=x, weights=\"imagenet\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "#model_cnidaria = make_model_mobilenetv2(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"simple\")\n",
        "#keras.utils.plot_model(model_cnidaria, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re run again with heavy\n",
        "model_cnidaria = make_model_mobilenetv2(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"heavy\")\n",
        "#keras.utils.plot_model(model_cnidaria, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u266NasabW2U",
        "outputId": "0d91b537-a379-411e-d3b8-db3fc946956f"
      },
      "id": "u266NasabW2U",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d8a3bda41a81>:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(include_top=False, input_tensor=x, weights=\"imagenet\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "197394bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "197394bc",
        "outputId": "c02fde3b-8aea-45c6-ec81-84fa62f1142e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9750 - loss: 0.0831\n",
            "Epoch 1: val_acc improved from -inf to 0.61111, saving model to best_model_cnidaria_mobilentv2_Heavy_50.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - acc: 0.9750 - loss: 0.0843 - val_acc: 0.6111 - val_loss: 3.4317\n",
            "Epoch 2/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9752 - loss: 0.0793\n",
            "Epoch 2: val_acc improved from 0.61111 to 0.62346, saving model to best_model_cnidaria_mobilentv2_Heavy_50.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3s/step - acc: 0.9751 - loss: 0.0791 - val_acc: 0.6235 - val_loss: 3.1061\n",
            "Epoch 3/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9828 - loss: 0.0805\n",
            "Epoch 3: val_acc improved from 0.62346 to 0.62963, saving model to best_model_cnidaria_mobilentv2_Heavy_50.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - acc: 0.9829 - loss: 0.0794 - val_acc: 0.6296 - val_loss: 2.9987\n",
            "Epoch 4/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9878 - loss: 0.0353\n",
            "Epoch 4: val_acc improved from 0.62963 to 0.64198, saving model to best_model_cnidaria_mobilentv2_Heavy_50.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - acc: 0.9875 - loss: 0.0369 - val_acc: 0.6420 - val_loss: 3.5280\n",
            "Epoch 5/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9834 - loss: 0.0553\n",
            "Epoch 5: val_acc did not improve from 0.64198\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - acc: 0.9832 - loss: 0.0559 - val_acc: 0.5864 - val_loss: 3.7909\n",
            "Epoch 6/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9573 - loss: 0.1308\n",
            "Epoch 6: val_acc improved from 0.64198 to 0.65432, saving model to best_model_cnidaria_mobilentv2_Heavy_50.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - acc: 0.9572 - loss: 0.1322 - val_acc: 0.6543 - val_loss: 3.8313\n",
            "Epoch 7/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9850 - loss: 0.0373\n",
            "Epoch 7: val_acc did not improve from 0.65432\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - acc: 0.9850 - loss: 0.0378 - val_acc: 0.6049 - val_loss: 3.6544\n",
            "Epoch 8/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9851 - loss: 0.0320\n",
            "Epoch 8: val_acc did not improve from 0.65432\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - acc: 0.9850 - loss: 0.0325 - val_acc: 0.6296 - val_loss: 4.0666\n",
            "Epoch 9/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9914 - loss: 0.0241\n",
            "Epoch 9: val_acc did not improve from 0.65432\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - acc: 0.9912 - loss: 0.0247 - val_acc: 0.5802 - val_loss: 4.1429\n",
            "Epoch 10/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - acc: 0.9805 - loss: 0.0977\n",
            "Epoch 10: val_acc did not improve from 0.65432\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - acc: 0.9807 - loss: 0.0967 - val_acc: 0.5802 - val_loss: 4.3297\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.80      0.71        45\n",
            "           1       0.62      0.68      0.65        19\n",
            "           2       0.56      1.00      0.71         5\n",
            "           3       0.75      0.86      0.80         7\n",
            "           4       0.56      0.25      0.34        20\n",
            "           5       0.50      1.00      0.67        11\n",
            "           6       1.00      0.75      0.86        12\n",
            "           7       1.00      0.25      0.40         4\n",
            "           8       0.67      0.50      0.57         4\n",
            "           9       1.00      0.60      0.75         5\n",
            "          10       0.71      0.29      0.42        17\n",
            "          11       0.75      0.67      0.71         9\n",
            "          12       0.67      1.00      0.80         4\n",
            "\n",
            "    accuracy                           0.65       162\n",
            "   macro avg       0.72      0.67      0.65       162\n",
            "weighted avg       0.68      0.65      0.63       162\n",
            "\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cnidaria_mobilentv2_Heavy_50.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "## change from keras example is the loss function as we deal with a lot of classes\n",
        "model_cnidaria.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "\n",
        "model_cnidaria.fit(\n",
        "    train_ds_cnidaria,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# get the clasification report\n",
        "best_model_example = keras.models.load_model(\"best_model_cnidaria_mobilentv2_Heavy_50.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = np.concatenate([y for x, y in val_ds_cnidaria], axis=0)\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "YtUw43AgGkpx"
      },
      "id": "YtUw43AgGkpx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments:\n",
        "1. randaugment: val_acc: 0.3827 (stopped early)\n",
        "2. heavy\n",
        "3. simple\n"
      ],
      "metadata": {
        "id": "Np_51Bti8buR"
      },
      "id": "Np_51Bti8buR"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "D3SAbxJpKfhP"
      },
      "id": "D3SAbxJpKfhP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to create ResNet50 model\n",
        "def make_model_resnet50(input_shape, num_classes, augmentation_type=\"simple\"):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = data_augmentation(inputs)\n",
        "    x = Rescaling(1./255)(x)\n",
        "    base_model = ResNet50(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "    # Additional preprocessing from imagenet\n",
        "    # run again without the prepocessing\n",
        "    #x = keras.applications.imagenet_utils.preprocess_input(x)\n",
        "    base_model.trainable = False  # Freeze for transfer learning\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.1)(x)  # Optional regularization\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "jIP8at5iAkg8"
      },
      "id": "jIP8at5iAkg8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model with heavy\n",
        "model_cnidaria = make_model_resnet50(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"heavy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6d1adb-a30c-4642-e461-fb69d6f54bc4",
        "id": "6oqtb8o6f72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "id": "6oqtb8o6f72a"
    },
    {
      "cell_type": "code",
      "source": [
        "#model_cnidaria = make_model_resnet50(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"randaugment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLG1Ud5LIHMi",
        "outputId": "3b6d1adb-a30c-4642-e461-fb69d6f54bc4"
      },
      "id": "pLG1Ud5LIHMi",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cnidaria_ResnNet50_random.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "## change from keras example is the loss function as we deal with a lot of classes\n",
        "model_cnidaria.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "\n",
        "model_cnidaria.fit(\n",
        "    train_ds_cnidaria,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# get the clasification report\n",
        "best_model_example = keras.models.load_model(\"best_model_cnidaria_ResnNet50_random.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = np.concatenate([y for x, y in val_ds_cnidaria], axis=0)\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uc3FzJOcKpDN",
        "outputId": "f88048fd-7608-4699-eeff-d11374b98986"
      },
      "id": "uc3FzJOcKpDN",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.2133 - loss: 3.1137\n",
            "Epoch 1: val_acc improved from -inf to 0.24691, saving model to best_model_cnidaria_ResnNet50_random.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 8s/step - acc: 0.2138 - loss: 3.1061 - val_acc: 0.2469 - val_loss: 2.8988\n",
            "Epoch 2/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.2517 - loss: 2.4711\n",
            "Epoch 2: val_acc did not improve from 0.24691\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 8s/step - acc: 0.2511 - loss: 2.4691 - val_acc: 0.2099 - val_loss: 2.4688\n",
            "Epoch 3/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.2575 - loss: 2.3738\n",
            "Epoch 3: val_acc improved from 0.24691 to 0.29630, saving model to best_model_cnidaria_ResnNet50_random.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 8s/step - acc: 0.2584 - loss: 2.3706 - val_acc: 0.2963 - val_loss: 2.2129\n",
            "Epoch 4/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3366 - loss: 2.2412\n",
            "Epoch 4: val_acc improved from 0.29630 to 0.34568, saving model to best_model_cnidaria_ResnNet50_random.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 8s/step - acc: 0.3355 - loss: 2.2428 - val_acc: 0.3457 - val_loss: 2.4126\n",
            "Epoch 5/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3179 - loss: 2.2921\n",
            "Epoch 5: val_acc improved from 0.34568 to 0.35185, saving model to best_model_cnidaria_ResnNet50_random.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 8s/step - acc: 0.3179 - loss: 2.2874 - val_acc: 0.3519 - val_loss: 2.1837\n",
            "Epoch 6/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3217 - loss: 2.0043\n",
            "Epoch 6: val_acc did not improve from 0.35185\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 8s/step - acc: 0.3217 - loss: 2.0048 - val_acc: 0.3086 - val_loss: 2.3230\n",
            "Epoch 7/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3657 - loss: 2.0405\n",
            "Epoch 7: val_acc did not improve from 0.35185\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 7s/step - acc: 0.3659 - loss: 2.0407 - val_acc: 0.3395 - val_loss: 2.3050\n",
            "Epoch 8/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3340 - loss: 2.1207\n",
            "Epoch 8: val_acc did not improve from 0.35185\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 8s/step - acc: 0.3344 - loss: 2.1172 - val_acc: 0.2654 - val_loss: 2.2986\n",
            "Epoch 9/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3374 - loss: 2.0427\n",
            "Epoch 9: val_acc improved from 0.35185 to 0.38889, saving model to best_model_cnidaria_ResnNet50_random.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 8s/step - acc: 0.3375 - loss: 2.0430 - val_acc: 0.3889 - val_loss: 2.3119\n",
            "Epoch 10/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.3486 - loss: 2.0419\n",
            "Epoch 10: val_acc did not improve from 0.38889\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 8s/step - acc: 0.3486 - loss: 2.0447 - val_acc: 0.3272 - val_loss: 2.7069\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.89      0.55        45\n",
            "           1       0.43      0.53      0.48        19\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.40      0.10      0.16        20\n",
            "           5       0.24      0.64      0.35        11\n",
            "           6       0.00      0.00      0.00        12\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.50      0.25      0.33         4\n",
            "           9       0.00      0.00      0.00         5\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       1.00      0.33      0.50         9\n",
            "          12       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.39       162\n",
            "   macro avg       0.23      0.21      0.18       162\n",
            "weighted avg       0.30      0.39      0.29       162\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNetB0"
      ],
      "metadata": {
        "id": "CQAIXuOzHJ_d"
      },
      "id": "CQAIXuOzHJ_d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments:\n",
        "1. simple: val_acc: 0.2716\n",
        "2. heavy: val_acc: 0.2778"
      ],
      "metadata": {
        "id": "kw1B6iok8t2h"
      },
      "id": "kw1B6iok8t2h"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "id": "GHIyMAQwN7C6"
      },
      "id": "GHIyMAQwN7C6",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to create EfficientNetB0 model\n",
        "def make_model_efficientnetb0(input_shape, num_classes, augmentation_type=\"simple\"):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = data_augmentation(inputs)\n",
        "    x = Rescaling(1./255)(x)\n",
        "    #x = keras.applications.imagenet_utils.preprocess_input(x) # using the preprocessing from imagenet\n",
        "    base_model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "    base_model.trainable = False  # Freeze for transfer learning\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.1)(x)  # Optional regularization\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "sEu6LdORK1_7"
      },
      "id": "sEu6LdORK1_7",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple was val_acc: 0.2716\n",
        "model_cnidaria = make_model_efficientnetb0(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"simple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozaYqwnQLGuu",
        "outputId": "dea1862c-4767-4647-8ff6-ee08da29769c"
      },
      "id": "ozaYqwnQLGuu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with heavy:\n",
        "#model_cnidaria = make_model_efficientnetb0(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"heavy\")"
      ],
      "metadata": {
        "id": "eqNedJs_1cud"
      },
      "id": "eqNedJs_1cud",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cnidaria_EfficientNetB0_heavy.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "## change from keras example is the loss function as we deal with a lot of classes\n",
        "model_cnidaria.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "\n",
        "model_cnidaria.fit(\n",
        "    train_ds_cnidaria,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# get the clasification report\n",
        "best_model_example = keras.models.load_model(\"best_model_cnidaria_EfficientNetB0_heavy.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "y_true = np.concatenate([y for x, y in val_ds_cnidaria], axis=0)\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSMXxPw_LMxZ",
        "outputId": "1a0c9a7b-f959-4b4a-ef09-5ec6fd6baf61",
        "collapsed": true
      },
      "id": "gSMXxPw_LMxZ",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1329 - loss: 4.6932\n",
            "Epoch 1: val_acc improved from -inf to 0.27778, saving model to best_model_cnidaria_EfficientNetB0_heavy.keras\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - acc: 0.1322 - loss: 4.6813 - val_acc: 0.2778 - val_loss: 3.5275\n",
            "Epoch 2/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1946 - loss: 3.1473\n",
            "Epoch 2: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4s/step - acc: 0.1940 - loss: 3.1402 - val_acc: 0.0556 - val_loss: 3.3098\n",
            "Epoch 3/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1699 - loss: 2.8621\n",
            "Epoch 3: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - acc: 0.1711 - loss: 2.8566 - val_acc: 0.0247 - val_loss: 2.9981\n",
            "Epoch 4/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1435 - loss: 2.8237\n",
            "Epoch 4: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 4s/step - acc: 0.1440 - loss: 2.8235 - val_acc: 0.1235 - val_loss: 2.6189\n",
            "Epoch 5/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1659 - loss: 2.7586\n",
            "Epoch 5: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - acc: 0.1669 - loss: 2.7573 - val_acc: 0.0432 - val_loss: 2.9977\n",
            "Epoch 6/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1859 - loss: 2.8251\n",
            "Epoch 6: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4s/step - acc: 0.1862 - loss: 2.8218 - val_acc: 0.2778 - val_loss: 2.6290\n",
            "Epoch 7/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1346 - loss: 2.8786\n",
            "Epoch 7: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 4s/step - acc: 0.1356 - loss: 2.8736 - val_acc: 0.0309 - val_loss: 2.9361\n",
            "Epoch 8/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.1316 - loss: 2.7687\n",
            "Epoch 8: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step - acc: 0.1320 - loss: 2.7700 - val_acc: 0.2778 - val_loss: 2.4132\n",
            "Epoch 9/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.2087 - loss: 2.9351\n",
            "Epoch 9: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 4s/step - acc: 0.2072 - loss: 2.9359 - val_acc: 0.2778 - val_loss: 2.9345\n",
            "Epoch 10/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.2072 - loss: 2.9278\n",
            "Epoch 10: val_acc did not improve from 0.27778\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 4s/step - acc: 0.2066 - loss: 2.9253 - val_acc: 0.1173 - val_loss: 2.8555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x784a4bc0f740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      1.00      0.43        45\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00        20\n",
            "           5       0.00      0.00      0.00        11\n",
            "           6       0.00      0.00      0.00        12\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.00      0.00      0.00         5\n",
            "          10       0.00      0.00      0.00        17\n",
            "          11       0.00      0.00      0.00         9\n",
            "          12       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.28       162\n",
            "   macro avg       0.02      0.08      0.03       162\n",
            "weighted avg       0.08      0.28      0.12       162\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "# Random over sampling of underrepresented families"
      ],
      "metadata": {
        "id": "zdMXptBacaoH"
      },
      "id": "zdMXptBacaoH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expirements:\n",
        "1. ResNet50: random augmentation"
      ],
      "metadata": {
        "id": "8W_7TyYaG1UX"
      },
      "id": "8W_7TyYaG1UX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check again to visualize the imbalance\n",
        "cnidaria_data = meta[meta['phylum'] == 'cnidaria']\n",
        "family_counts = cnidaria_data['family'].value_counts().reset_index()\n",
        "family_counts.columns = ['family', 'appearances']\n",
        "\n",
        "family_counts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "eVcj94b0mjs6",
        "outputId": "ef3524f2-b55d-4041-c3eb-c8cde1f7e62a"
      },
      "id": "eVcj94b0mjs6",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              family  appearances\n",
              "0        acroporidae          210\n",
              "1        agariciidae          120\n",
              "2       euphylliidae           90\n",
              "3     pocilloporidae           60\n",
              "4           faviidae           60\n",
              "5        merulinidae           60\n",
              "6     siderastreidae           30\n",
              "7          fungiidae           30\n",
              "8     lobophylliidae           30\n",
              "9   dendrophylliidae           30\n",
              "10      helioporidae           30\n",
              "11   diploastraeidae           30\n",
              "12      meandrinidae           30"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59a08de3-42d8-44d1-8200-cb54bbc849d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>family</th>\n",
              "      <th>appearances</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acroporidae</td>\n",
              "      <td>210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>agariciidae</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>euphylliidae</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pocilloporidae</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>faviidae</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>merulinidae</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>siderastreidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fungiidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lobophylliidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dendrophylliidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>helioporidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>diploastraeidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>meandrinidae</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59a08de3-42d8-44d1-8200-cb54bbc849d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59a08de3-42d8-44d1-8200-cb54bbc849d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59a08de3-42d8-44d1-8200-cb54bbc849d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3dd8d35a-8b4e-423a-bcac-715f56578a58\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dd8d35a-8b4e-423a-bcac-715f56578a58')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3dd8d35a-8b4e-423a-bcac-715f56578a58 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3bb445f5-6bd0-44ff-ad90-e7559c105d7f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('family_counts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3bb445f5-6bd0-44ff-ad90-e7559c105d7f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('family_counts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "family_counts",
              "summary": "{\n  \"name\": \"family_counts\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"family\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"diploastraeidae\",\n          \"dendrophylliidae\",\n          \"acroporidae\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"appearances\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 30,\n        \"max\": 210,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          120,\n          30,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Random Over Sampler was adapted from this Documentation:\n",
        "https://imbalanced-learn.org/stable/over_sampling.html"
      ],
      "metadata": {
        "id": "OAbDE7h2hf72"
      },
      "id": "OAbDE7h2hf72"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert the dataset to NumPy arrays for RandomOverSampler\n",
        "X_train = []\n",
        "y_train = []\n",
        "for images, labels in train_ds_cnidaria:\n",
        "    X_train.extend(images.numpy())\n",
        "    y_train.extend(labels.numpy())\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train) # Encode labels to numerical values\n",
        "\n",
        "# Oversample with seed 42 for reproducability\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train_encoded)\n",
        "\n",
        "# Reshape back to initial image shape\n",
        "X_train_resampled = X_train_resampled.reshape(-1, 224, 224, 3)\n",
        "\n",
        "# Convert back to TensorFlow dataset\n",
        "train_ds_cnidaria_resampled = tf_data.Dataset.from_tensor_slices((X_train_resampled, y_train_resampled))\n",
        "train_ds_cnidaria_resampled = train_ds_cnidaria_resampled.batch(batch_size)\n"
      ],
      "metadata": {
        "id": "YSt2AZkeEyT8"
      },
      "id": "YSt2AZkeEyT8",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_cnidaria_resampled"
      ],
      "metadata": {
        "id": "Z7lGjg7mIdxV",
        "outputId": "87d56148-9283-435c-9de9-b79a9fa0c511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Z7lGjg7mIdxV",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_cnidaria = make_model_resnet50(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"randaugment\")"
      ],
      "metadata": {
        "id": "KGaFg-JlFNF8"
      },
      "id": "KGaFg-JlFNF8",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cnidaria_ResNet50_rand_oversampling.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "## change from keras example is the loss function as we deal with a lot of classes\n",
        "model_cnidaria.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "\n",
        "model_cnidaria.fit(\n",
        "    train_ds_cnidaria_resampled,  # Use the resampled dataset\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# Get the classification report\n",
        "best_model_example = keras.models.load_model(\"best_model_cnidaria_ResNet50_rand_oversampling.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred_encoded = np.argmax(y_pred_probs, axis=1)  # Predictions are still encoded\n",
        "\n",
        "# Inverse transform to get original labels\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "y_true = label_encoder.inverse_transform(np.concatenate([y for x, y in val_ds_cnidaria], axis=0))\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "tOPBd5XwFYaZ",
        "outputId": "efb0a843-a180-4204-a9e6-4ffc1e504947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tOPBd5XwFYaZ",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - acc: 0.1823 - loss: 5.6903\n",
            "Epoch 1: val_acc improved from -inf to 0.05556, saving model to best_model_cnidaria_ResNet50_rand_oversampling.keras\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 6s/step - acc: 0.1813 - loss: 5.7673 - val_acc: 0.0556 - val_loss: 22.9902\n",
            "Epoch 2/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.0915 - loss: 15.7245\n",
            "Epoch 2: val_acc did not improve from 0.05556\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 6s/step - acc: 0.0911 - loss: 15.7049 - val_acc: 0.0556 - val_loss: 23.9672\n",
            "Epoch 3/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - acc: 0.1224 - loss: 15.4095\n",
            "Epoch 3: val_acc improved from 0.05556 to 0.06790, saving model to best_model_cnidaria_ResNet50_rand_oversampling.keras\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 6s/step - acc: 0.1221 - loss: 15.3853 - val_acc: 0.0679 - val_loss: 22.0680\n",
            "Epoch 4/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - acc: 0.1638 - loss: 13.2652\n",
            "Epoch 4: val_acc improved from 0.06790 to 0.08642, saving model to best_model_cnidaria_ResNet50_rand_oversampling.keras\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 6s/step - acc: 0.1635 - loss: 13.2530 - val_acc: 0.0864 - val_loss: 14.7760\n",
            "Epoch 5/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1696 - loss: 12.1295\n",
            "Epoch 5: val_acc did not improve from 0.08642\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 6s/step - acc: 0.1692 - loss: 12.1212 - val_acc: 0.0864 - val_loss: 19.0480\n",
            "Epoch 6/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1663 - loss: 14.0882\n",
            "Epoch 6: val_acc did not improve from 0.08642\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 7s/step - acc: 0.1661 - loss: 14.0647 - val_acc: 0.0617 - val_loss: 25.4653\n",
            "Epoch 7/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1946 - loss: 16.0893\n",
            "Epoch 7: val_acc improved from 0.08642 to 0.09877, saving model to best_model_cnidaria_ResNet50_rand_oversampling.keras\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 7s/step - acc: 0.1946 - loss: 16.0449 - val_acc: 0.0988 - val_loss: 22.7892\n",
            "Epoch 8/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1836 - loss: 12.4493\n",
            "Epoch 8: val_acc improved from 0.09877 to 0.14815, saving model to best_model_cnidaria_ResNet50_rand_oversampling.keras\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 7s/step - acc: 0.1833 - loss: 12.4337 - val_acc: 0.1481 - val_loss: 17.1024\n",
            "Epoch 9/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1531 - loss: 11.4514\n",
            "Epoch 9: val_acc did not improve from 0.14815\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 7s/step - acc: 0.1529 - loss: 11.4460 - val_acc: 0.0988 - val_loss: 18.7159\n",
            "Epoch 10/10\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - acc: 0.1517 - loss: 13.4953\n",
            "Epoch 10: val_acc did not improve from 0.14815\n",
            "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 6s/step - acc: 0.1516 - loss: 13.4750 - val_acc: 0.1420 - val_loss: 18.9522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x784a4759a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        45\n",
            "           1       0.00      0.00      0.00        19\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         7\n",
            "           4       0.00      0.00      0.00        20\n",
            "           5       0.00      0.00      0.00        11\n",
            "           6       0.00      0.00      0.00        12\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.16      1.00      0.28         5\n",
            "          10       0.14      0.76      0.23        17\n",
            "          11       0.17      0.67      0.27         9\n",
            "          12       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.15       162\n",
            "   macro avg       0.04      0.19      0.06       162\n",
            "weighted avg       0.03      0.15      0.05       162\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "# SMOTE"
      ],
      "metadata": {
        "id": "j5F51R_PQW5n"
      },
      "id": "j5F51R_PQW5n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiments:\n",
        "1. MobileNetV2 with simple augmentations (previous functions)\n",
        "2. After reasearch found, that SMOTE can't work for our problem, because: SMOTE works by interpolating between feature vectors — and in the case of image data, flattening breaks the spatial structure, and interpolating pixel-by-pixel can create non-realistic or corrupted images that don't follow the original data distribution."
      ],
      "metadata": {
        "id": "9jRDhizXQpOf"
      },
      "id": "9jRDhizXQpOf"
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2  # Using MobileNetV2 for simplicity\n",
        "\n",
        "\n",
        "epochs= 10\n",
        "\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"cnidaria_ResNet50_rand_oversampling_heavy.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "# Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train_encoded)\n",
        "X_train_resampled = X_train_resampled.reshape(-1, image_size[0], image_size[1], 3) # Reshape back to image dimensions\n",
        "\n",
        "\n",
        "# use mobiletnetv4 model from pervious runs\n",
        "#model = make_model_mobilenetv2(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"simple\")\n",
        "model = make_model_mobilenetv2(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"heavy\")\n",
        "\n",
        "# compile\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "#fit\n",
        "model.fit(\n",
        "    train_ds_cnidaria_resampled,  # Use the resampled dataset\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# Get the classification report\n",
        "best_model_example = keras.models.load_model(\"cnidaria_ResNet50_rand_oversampling_heavy.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred_encoded = np.argmax(y_pred_probs, axis=1)  # Predictions are still encoded\n",
        "\n",
        "# Inverse transform to get original labels\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "y_true = label_encoder.inverse_transform(np.concatenate([y for x, y in val_ds_cnidaria], axis=0))\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "OVA37vtAQWpN",
        "outputId": "bc5d29f0-c64b-470c-da4f-7461c9596164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "id": "OVA37vtAQWpN",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-d8a3bda41a81>:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(include_top=False, input_tensor=x, weights=\"imagenet\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m44/68\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 6s/step - acc: 0.2311 - loss: 8.3210"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8814d2c09c02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m model_cnidaria.fit(\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mtrain_ds_cnidaria_resampled\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use the resampled dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___________\n",
        "# Oversampling by duplication"
      ],
      "metadata": {
        "id": "H7P4L7kBlhnt"
      },
      "id": "H7P4L7kBlhnt"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "X_train_image_list = []\n",
        "y_train_label_list = []\n",
        "# Extract images and labels from train_ds_cnidaria\n",
        "for images, labels in train_ds_cnidaria:\n",
        "    X_train_image_list.append(images.numpy())\n",
        "    y_train_label_list.append(labels.numpy())\n",
        "# concatenate the images and labels\n",
        "X_train = np.concatenate(X_train_image_list, axis=0)\n",
        "y_train = np.concatenate(y_train_label_list, axis=0)\n",
        "\n",
        "# encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Check original class distribution\n",
        "counter = Counter(y_train_encoded)\n",
        "print(\"Class distribution:\", counter)"
      ],
      "metadata": {
        "id": "-QYh1WPflhbl",
        "outputId": "5e9fb233-5bf1-49f7-c262-95ab1e58cfaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-QYh1WPflhbl",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: Counter({np.int64(0): 165, np.int64(1): 101, np.int64(4): 70, np.int64(11): 51, np.int64(5): 49, np.int64(10): 43, np.int64(8): 26, np.int64(7): 26, np.int64(12): 26, np.int64(2): 25, np.int64(9): 25, np.int64(3): 23, np.int64(6): 18})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find max class count\n",
        "max_count = max(counter.values())\n",
        "\n",
        "# Oversample by duplication\n",
        "X_train_oversampled = []\n",
        "y_train_oversampled = []\n",
        "\n",
        "for label in np.unique(y_train_encoded):\n",
        "    # index  = indices belonging to current label\n",
        "    index = np.where(y_train_encoded == label)[0]\n",
        "    n_to_add = max_count - len(index )\n",
        "    # calculate how many samples need to be added to current class\n",
        "    if n_to_add > 0:\n",
        "        dup_indices = np.random.choice(index , size=n_to_add, replace=True) # randomly choose label to add from the available onces\n",
        "        X_dup = X_train[dup_indices]\n",
        "        y_dup = y_train_encoded[dup_indices]\n",
        "        # concat samples to the list\n",
        "        X_train_oversampled.append(np.concatenate([X_train[index ], X_dup], axis=0))\n",
        "        y_train_oversampled.append(np.concatenate([y_train_encoded[index ], y_dup], axis=0))\n",
        "    else:\n",
        "        X_train_oversampled.append(X_train[index ])\n",
        "        y_train_oversampled.append(y_train_encoded[index ])\n",
        "\n",
        "# Combine all classes\n",
        "X_train_oversampled = np.concatenate(X_train_oversampled, axis=0)\n",
        "y_train_oversampled = np.concatenate(y_train_oversampled, axis=0)\n",
        "\n",
        "# Convert back to tf.data.Dataset -> decoding the labe names\n",
        "train_ds_cnidaria_oversampled = tf.data.Dataset.from_tensor_slices((X_train_oversampled, y_train_oversampled))\n",
        "#train_ds_cnidaria_oversampled = train_ds_cnidaria_oversampled.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "# Check new distribution\n",
        "print(\"New class distribution:\", Counter(y_train_oversampled))"
      ],
      "metadata": {
        "id": "92t4lkgdkiJE",
        "outputId": "bebcf26b-2bfa-49ad-e123-f0f5c7d761d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "id": "92t4lkgdkiJE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'counter' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ebe21f17deb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find max class count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Oversample by duplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_oversampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_cnidaria_oversampled"
      ],
      "metadata": {
        "id": "WsiQzNQclm5V",
        "outputId": "ebc97c21-06da-42e1-ba0a-bfa4446df465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "id": "WsiQzNQclm5V",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_ds_cnidaria_oversampled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7a65f5ac8eb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds_cnidaria_oversampled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ds_cnidaria_oversampled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we should have 165 of each family"
      ],
      "metadata": {
        "id": "CkUwfsRak-PI"
      },
      "id": "CkUwfsRak-PI"
    },
    {
      "cell_type": "code",
      "source": [
        "epoch=10\n",
        "callbacks = [\n",
        "    # saves the best model of the run using max val_accuracy as a metric\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model_cnidaria_ResNet50_oversampling_duplication.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        verbose=1)\n",
        "    ]\n",
        "\n",
        "# re create the model\n",
        "model = make_model_resnet50(input_shape=image_size + (3,), num_classes=13, augmentation_type=\"simple\")\n",
        "\n",
        "\n",
        "## change from keras example is the loss function as we deal with a lot of classes\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), ## change this CategoricalCrossentropy to the the one it is now\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")], ## change this CategoricalCrossentropy to the the one it is now\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_ds_cnidaria_oversampled,  # Oversampled data for training\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds_cnidaria,\n",
        ")\n",
        "\n",
        "# Get the classification report\n",
        "best_model_example = keras.models.load_model(\"best_model_cnidaria_ResNet50_oversampling_duplication.keras\")\n",
        "y_pred_probs = best_model_example.predict(val_ds_cnidaria)\n",
        "y_pred_encoded = np.argmax(y_pred_probs, axis=1)  # Predictions are still encoded\n",
        "\n",
        "# Inverse transform to get original labels\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "y_true = label_encoder.inverse_transform(np.concatenate([y for x, y in val_ds_cnidaria], axis=0))\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "MHMCmTjHl6Nn",
        "outputId": "02db593b-7e53-45d3-85d0-2af277da356a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "id": "MHMCmTjHl6Nn",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m 4/68\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:32\u001b[0m 5s/step - acc: 0.1152 - loss: 3.3462"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-77ce422641dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_ds_cnidaria_oversampled\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Oversampled data for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}